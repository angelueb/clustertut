<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.110.0">
    <meta name="generator" content="Relearn 5.11.2+tip">
    <meta name="description" content="">
    <title>GPU job: RL-Medical with conda :: UEB cluster usage tutorial</title>
    <!-- https://github.com/filamentgroup/loadCSS/blob/master/README.md#how-to-use -->
    <link href="/clustertut/css/fontawesome-all.min.css?1683059873" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/clustertut/css/fontawesome-all.min.css?1683059873" rel="stylesheet"></noscript>
    <link href="/clustertut/css/nucleus.css?1683059873" rel="stylesheet">
    <link href="/clustertut/css/auto-complete.css?1683059873" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/clustertut/css/auto-complete.css?1683059873" rel="stylesheet"></noscript>
    <link href="/clustertut/css/perfect-scrollbar.min.css?1683059873" rel="stylesheet">
    <link href="/clustertut/css/fonts.css?1683059873" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/clustertut/css/fonts.css?1683059873" rel="stylesheet"></noscript>
    <link href="/clustertut/css/theme.css?1683059873" rel="stylesheet">
    <link href="/clustertut/css/theme-learn.css?1683059873" rel="stylesheet" id="variant-style">
    <link href="/clustertut/css/variant.css?1683059873" rel="stylesheet">
    <link href="/clustertut/css/print.css?1683059873" rel="stylesheet" media="print">
    <link href="/clustertut/css/ie.css?1683059873" rel="stylesheet">
    <script src="/clustertut/js/url.js?1683059873"></script>
    <script src="/clustertut/js/variant.js?1683059873"></script>
    <script>
      // hack to let hugo tell us how to get to the root when using relativeURLs, it needs to be called *url= for it to do its magic:
      // https://github.com/gohugoio/hugo/blob/145b3fcce35fbac25c7033c91c1b7ae6d1179da8/transform/urlreplacers/absurlreplacer.go#L72
      window.index_js_url="/clustertut/index.search.js";
      var root_url="/";
      var baseUri=root_url.replace(/\/$/, '');
      // translations
      window.T_Copy_to_clipboard = 'Copy to clipboard';
      window.T_Copied_to_clipboard = 'Copied to clipboard!';
      window.T_Copy_link_to_clipboard = 'Copy link to clipboard';
      window.T_Link_copied_to_clipboard = 'Copied link to clipboard!';
      window.T_No_results_found = 'No results found for \u0022{0}\u0022';
      window.T_N_results_found = '{1} results found for \u0022{0}\u0022';
      // some further base stuff
      var baseUriFull='https:\/\/angelueb.github.io\/clustertut/';
      window.variants && variants.init( [ 'learn' ] );
    </script>
  </head>
  <body class="mobile-support html" data-url="/clustertut/practical-examples/example_gpu-conda/index.html">
    <div id="body" class="default-animation">
      <div id="sidebar-overlay"></div>
      <div id="toc-overlay"></div>
      <nav id="topbar" class="highlightable">
        <div>
          <div class="navigation">
            <span class="nav nav-next topbar-link"><i class="fa fa-chevron-right fa-fw"></i></span>
          </div>
          <div class="navigation">
            <a class="nav nav-prev topbar-link" href="/clustertut/practical-examples/example_singularity/index.html" title="Singularity: Quasi-mapping RNA-Seq quantification (&#129104;)"><i class="fas fa-chevron-left fa-fw"></i></a>
          </div>
          <div id="breadcrumbs">
            <span id="sidebar-toggle-span">
              <a href="#" id="sidebar-toggle" class="topbar-link" title='Menu (CTRL+ALT+n)'><i class="fas fa-bars fa-fw"></i></a>
            </span>
            <span id="toc-menu" title='Table of Contents (CTRL+ALT+t)'><i class="fas fa-list-alt fa-fw"></i></span>
            <ol class="links" itemscope itemtype="http://schema.org/BreadcrumbList">
              <li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><a itemprop="item" href="/clustertut/index.html"><span itemprop="name">UEB Cluster Basic Tutorial</span></a><meta itemprop="position" content="1"> > </li>
              <li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><a itemprop="item" href="/clustertut/practical-examples/index.html"><span itemprop="name">Practical Examples</span></a><meta itemprop="position" content="2"> > </li>
              <li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><span itemprop="name">GPU job: RL-Medical with conda</span><meta itemprop="position" content="3"></li>
            </ol>
          </div>
          <div class="default-animation progress">
            <div class="toc-wrapper"><nav id="TableOfContents">
  <ul>
    <li><a href="#installing-miniconda">Installing Miniconda</a></li>
    <li><a href="#cloning-the-rl-medical-github-repository">Cloning the RL-Medical Github repository</a></li>
    <li><a href="#submitting-a-gpgpu-job">Submitting a GPGPU job</a>
      <ul>
        <li><a href="#choosing-the-right-slurm-partition">Choosing the right SLURM partition</a></li>
        <li><a href="#creating-a-job-submission-file">Creating a job submission file</a></li>
        <li><a href="#submitting-and-monitoring-the-slurm-job">Submitting and monitoring the SLURM job</a></li>
      </ul>
    </li>
  </ul>
</nav>
            </div>
          </div>
        </div>
      </nav>
      <main id="body-inner" class="highlightable default" tabindex="-1">
        <div class="flex-block-wrapper">
          <div id="head-tags">
          </div>
          <article class="default">
<h1 id="gpu-job-rl-medical-with-conda">GPU job: RL-Medical with conda</h1>

<p>Although Singularity is the recommended way to run tools on the cluster without the need of requesting administrators a system-wide installation, you can also use <strong><a href="https://docs.conda.io/en/latest/" target="_blank">Conda</a></strong>-based installations and environments. Please note that, as with any other kind of user-level locally installed software, we can offer limited support.</p>
<h2 id="installing-miniconda">Installing Miniconda</h2>
<p>We are going to install <strong><a href="https://docs.conda.io/en/latest/miniconda.html" target="_blank">Miniconda</a></strong>, which is a lightweight Conda distribution. We recommend it, since Miniconda initial installation requires much less disk space than the full Conda distribution, and disk space on the cluster is a limited resource (of course, with Miniconda you can install additional packages whenever you need them).</p>
<p>First, we download the Miniconda installation script:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$ wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
</span></span><span style="display:flex;"><span>--2023-04-27 20:07:18--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
</span></span><span style="display:flex;"><span>Resolving repo.anaconda.com <span style="color:#f92672">(</span>repo.anaconda.com<span style="color:#f92672">)</span>... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8203, ...
</span></span><span style="display:flex;"><span>Connecting to repo.anaconda.com <span style="color:#f92672">(</span>repo.anaconda.com<span style="color:#f92672">)</span>|104.16.131.3|:443... connected.
</span></span><span style="display:flex;"><span>HTTP request sent, awaiting response... <span style="color:#ae81ff">200</span> OK
</span></span><span style="display:flex;"><span>Length: <span style="color:#ae81ff">73134376</span> <span style="color:#f92672">(</span>70M<span style="color:#f92672">)</span> <span style="color:#f92672">[</span>application/x-sh<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Miniconda3-latest-Linux-x86_64 100%<span style="color:#f92672">[===================================================</span>&gt;<span style="color:#f92672">]</span>  69.75M  23.8MB/s    in 2.9s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>2023-04-27 20:07:21 <span style="color:#f92672">(</span>23.8 MB/s<span style="color:#f92672">)</span> - ‘Miniconda3-latest-Linux-x86_64.sh’ saved <span style="color:#f92672">[</span>73134376/73134376<span style="color:#f92672">]</span>
</span></span></code></pre></div><p>Now we install it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$ bash Miniconda3-latest-Linux-x86_64.sh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Welcome to Miniconda3 py310_23.3.1-0 
</span></span></code></pre></div><p>After accepting reviewing and accepting the license, confirm the default install location (which is in your home directory) and complete the installation (the remaining default options are fine, but anyway you can change them later).</p>
<p>Now, exit your session&hellip;</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$ exit
</span></span></code></pre></div><p>and log in again. You should see your command prompt indicating now that the &lsquo;base&rsquo; Conda environment is activated by default:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">(</span>base<span style="color:#f92672">)</span> <span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$
</span></span></code></pre></div><p>You can prevent this environment to be activated on startup with this command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>conda config --set auto_activate_base false
</span></span></code></pre></div><p>Exit en log in again to check it.</p>
<h2 id="cloning-the-rl-medical-github-repository">Cloning the RL-Medical Github repository</h2>
<p>Next, we get the RL-Medical code from Github. Since in this example we are going to use the sample data that comes with the tool, we are going to place it in the <code>/cscratch</code> storage system:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$ cd /cscratch/angel/tutorial/
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna tutorial<span style="color:#f92672">]</span>$ git clone https://github.com/gml16/rl-medical.git
</span></span><span style="display:flex;"><span>Cloning into <span style="color:#e6db74">&#39;rl-medical&#39;</span>...
</span></span><span style="display:flex;"><span>remote: Enumerating objects: 2699, <span style="color:#66d9ef">done</span>.
</span></span><span style="display:flex;"><span>remote: Counting objects: 100% <span style="color:#f92672">(</span>275/275<span style="color:#f92672">)</span>, <span style="color:#66d9ef">done</span>.
</span></span><span style="display:flex;"><span>remote: Compressing objects: 100% <span style="color:#f92672">(</span>20/20<span style="color:#f92672">)</span>, <span style="color:#66d9ef">done</span>.
</span></span><span style="display:flex;"><span>remote: Total <span style="color:#ae81ff">2699</span> <span style="color:#f92672">(</span>delta 262<span style="color:#f92672">)</span>, reused <span style="color:#ae81ff">257</span> <span style="color:#f92672">(</span>delta 255<span style="color:#f92672">)</span>, pack-reused <span style="color:#ae81ff">2424</span>
</span></span><span style="display:flex;"><span>Receiving objects: 100% <span style="color:#f92672">(</span>2699/2699<span style="color:#f92672">)</span>, 194.17 MiB | 9.38 MiB/s, <span style="color:#66d9ef">done</span>.
</span></span><span style="display:flex;"><span>Resolving deltas: 100% <span style="color:#f92672">(</span>1693/1693<span style="color:#f92672">)</span>, <span style="color:#66d9ef">done</span>.
</span></span><span style="display:flex;"><span>Updating files: 100% <span style="color:#f92672">(</span>56/56<span style="color:#f92672">)</span>, <span style="color:#66d9ef">done</span>.
</span></span></code></pre></div><p>Please remember: You should run your jobs using input data from your <code>/cscratch/&lt;yourusername&gt;</code> directory, and also direct your output files to your <code>/cscratch/&lt;yourusername&gt;</code> directory. Once your computing jobs are not using a set of data from your <code>/cscratch/&lt;yourusername&gt;</code> or producing data into it anymore, this specific data should be moved as soon as possible to your local device and removed from the cluster.</p>
<p>With the repository cloned, we get into the newly created <code>rl-medical</code> directory, and use the file &rsquo;environment.yml&rsquo; to automatically create the Conda environment with all the dependencies needed to run the tool. You can find these instructions on the <strong><a href="https://github.com/gml16/rl-medical" target="_blank">Github repository of the tool</a></strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna tutorial<span style="color:#f92672">]</span>$ cd rl-medical/
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna rl-medical<span style="color:#f92672">]</span>$ conda env create -f environment.yml
</span></span><span style="display:flex;"><span>Retrieving notices: ...working... <span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>Collecting package metadata <span style="color:#f92672">(</span>repodata.json<span style="color:#f92672">)</span>: <span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>Solving environment: <span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Downloading and Extracting Packages
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>Wait until all the packages are downloaded and properly installed.</p>
<h2 id="submitting-a-gpgpu-job">Submitting a GPGPU job</h2>
<h3 id="choosing-the-right-slurm-partition">Choosing the right SLURM partition</h3>
<p>Remember that in order run our computing jobs, we need to submit them to <strong><a href="https://slurm.schedmd.com/" target="_blank">SLURM</a></strong> (our cluster&rsquo;s resource and job management system). In this example, we need to use GPU resources to run our job, which means that we need to send the job to the right partition. In SLURM, partitions are simply sets of computing machines that are logically grouped so that SLURM can schedule and execute computing jobs on them according to some particular criteria (like availability of specific hardware resources, maximum length of the jobs, etc). In our cluster there are two partitions, as the <code>sinfo</code> command shows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$ sinfo
</span></span><span style="display:flex;"><span>PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST
</span></span><span style="display:flex;"><span>regular*     up 1-00:00:00      <span style="color:#ae81ff">1</span>   idle c01
</span></span><span style="display:flex;"><span>gpgpu        up 1-00:00:00      <span style="color:#ae81ff">1</span>   idle g01
</span></span></code></pre></div><p>In our case we need to use the <code>gpgpu</code> partition, since its nodes have GPU hardware resources available for SLURM to use. We can get more specific information about the <code>g01</code> node, which is a member of the <code>gpgpu</code>partition:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$ scontrol show node g01
</span></span><span style="display:flex;"><span>NodeName<span style="color:#f92672">=</span>g01 Arch<span style="color:#f92672">=</span>x86_64 CoresPerSocket<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>   CPUAlloc<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> CPUEfctv<span style="color:#f92672">=</span><span style="color:#ae81ff">24</span> CPUTot<span style="color:#f92672">=</span><span style="color:#ae81ff">24</span> CPULoad<span style="color:#f92672">=</span>0.00
</span></span><span style="display:flex;"><span>   AvailableFeatures<span style="color:#f92672">=(</span>null<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>   ActiveFeatures<span style="color:#f92672">=(</span>null<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>   Gres<span style="color:#f92672">=</span>gpu:ampere:2<span style="color:#f92672">(</span>S:0<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>   NodeAddr<span style="color:#f92672">=</span>g01 NodeHostName<span style="color:#f92672">=</span>g01 Version<span style="color:#f92672">=</span>22.05.2
</span></span><span style="display:flex;"><span>   OS<span style="color:#f92672">=</span>Linux 4.18.0-372.19.1.el8_6.x86_64 <span style="color:#75715e">#1 SMP Tue Aug 2 16:19:42 UTC 2022</span>
</span></span><span style="display:flex;"><span>   RealMemory<span style="color:#f92672">=</span><span style="color:#ae81ff">121856</span> AllocMem<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> FreeMem<span style="color:#f92672">=</span><span style="color:#ae81ff">127045</span> Sockets<span style="color:#f92672">=</span><span style="color:#ae81ff">24</span> Boards<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>   State<span style="color:#f92672">=</span>IDLE ThreadsPerCore<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> TmpDisk<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> Weight<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> Owner<span style="color:#f92672">=</span>N/A MCS_label<span style="color:#f92672">=</span>N/A
</span></span><span style="display:flex;"><span>   Partitions<span style="color:#f92672">=</span>gpgpu
</span></span><span style="display:flex;"><span>   BootTime<span style="color:#f92672">=</span>2023-02-13T21:25:58 SlurmdStartTime<span style="color:#f92672">=</span>2023-02-14T00:25:43
</span></span><span style="display:flex;"><span>   LastBusyTime<span style="color:#f92672">=</span>2023-02-26T02:14:04
</span></span><span style="display:flex;"><span>   CfgTRES<span style="color:#f92672">=</span>cpu<span style="color:#f92672">=</span>24,mem<span style="color:#f92672">=</span>119G,billing<span style="color:#f92672">=</span><span style="color:#ae81ff">24</span>
</span></span><span style="display:flex;"><span>   AllocTRES<span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>   CapWatts<span style="color:#f92672">=</span>n/a
</span></span><span style="display:flex;"><span>   CurrentWatts<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> AveWatts<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>   ExtSensorsJoules<span style="color:#f92672">=</span>n/s ExtSensorsWatts<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> ExtSensorsTemp<span style="color:#f92672">=</span>n/s
</span></span></code></pre></div><p>Note the <code>Gres=gpu:ampere:2(S:0)</code> line, which means that this particular node has 2 GPUs (in this case, a description of the type, <code>ampere</code>, is included).</p>
<h3 id="creating-a-job-submission-file">Creating a job submission file</h3>
<p>Essentially, there are two ways of submitting computing jobs to SLURM, an interactive and a batch mode. The latter is more flexible and less error-prone, specially for less experienced users, so it&rsquo;s the way we&rsquo;re going to use for this example.</p>
<p>First, we need to create a job script, which is simply a plain text file containing some SLURM directives and parameters and the actual command of the tool (or tools) to run. You can create this file using any plain text editor. You can use <strong><a href="https://nano-editor.org/" target="_blank">nano</a></strong> or <strong><a href="https://www.vim.org/" target="_blank">vim</a></strong> for instance, directly from the command line interface while you&rsquo;re connected to the cluster. Also, you can create it on your local computer and then transfer it to cluster.</p>
<p>For example, to create job script with the nano editor named <code>rl-medical_train.run</code> and start editing it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$ nano rl-medical_train.run
</span></span></code></pre></div><p>Please, refer to the <strong><a href="https://nano-editor.org/docs.php" target="_blank">nano</a></strong> documentation to learn how to use the editor if you are not familiar with it (remember that you can use any other plain text editor)</p>
<p>In our example, we are going to use the following contents for our job script:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">#!/bin/bash
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">##This is an example of a simple GPU job</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH -p gpgpu       # partition name</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH -c 10            # number of CPU cores or threads requested</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --mem 30G        # RAM requested</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --gres=gpu:1     # Requesting to use GPU resources, and how many</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --job-name rlmedical-train01                # Job name</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH -o job.%j.out               # File to which standard out will be written</span>
</span></span><span style="display:flex;"><span>                                    <span style="color:#75715e"># (%j is replaced automatically by the SLURM&#39;s job ID)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH -e job.%j.err               # File to which standard err will be written</span>
</span></span><span style="display:flex;"><span>                                    <span style="color:#75715e"># (%j is replaced automatically by the SLURM&#39;s job ID)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Initialize Conda and activate the rl-medical environment</span>
</span></span><span style="display:flex;"><span>. /home/<span style="color:#e6db74">${</span>USER<span style="color:#e6db74">}</span>/miniconda3/etc/profile.d/conda.sh
</span></span><span style="display:flex;"><span>conda activate rl-medical
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Enter the directory where the main RL-Medical python script is.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## This is needed since the input filenames that RL-Medical uses as test data</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## are specified using relative paths (which is NOT a specially good practice).</span>
</span></span><span style="display:flex;"><span>cd /cscratch/angel/tutorial/rl-medical/src
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Input variables. </span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## (remember that any output data should be also stored in your /cscratch directory)</span>
</span></span><span style="display:flex;"><span>IMGFILES<span style="color:#f92672">=</span>data/filenames/image_files.txt
</span></span><span style="display:flex;"><span>LANDMARKFILES<span style="color:#f92672">=</span>data/filenames/landmark_files.txt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Run RL-Medical in &#39;train&#39; mode and exit the conda environment</span>
</span></span><span style="display:flex;"><span>python DQN.py --task train --memory_size <span style="color:#ae81ff">30000</span> --init_memory_size <span style="color:#ae81ff">20000</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--files $IMGFILES $LANDMARKFILES --model_name CommNet --file_type brain <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--landmarks <span style="color:#ae81ff">13</span> <span style="color:#ae81ff">14</span> <span style="color:#ae81ff">0</span> <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">2</span> --multiscale --viz <span style="color:#ae81ff">0</span> --train_freq <span style="color:#ae81ff">50</span> --write
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>conda deactivate
</span></span></code></pre></div><h3 id="submitting-and-monitoring-the-slurm-job">Submitting and monitoring the SLURM job</h3>
<p>Now let&rsquo;s submit our job to SLURM using the job script we&rsquo;ve just created, with the <strong><a href="https://slurm.schedmd.com/sbatch.html" target="_blank"><code>sbatch</code></a></strong> command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$ sbatch rl-medical_train.run
</span></span><span style="display:flex;"><span>Submitted batch job <span style="color:#ae81ff">208</span>
</span></span></code></pre></div><p>Note that SLURM is reporting the ID of our job, 208.</p>
<p>Next we can check the state of our job:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$ squeue -u angel
</span></span><span style="display:flex;"><span>             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST<span style="color:#f92672">(</span>REASON<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>               <span style="color:#ae81ff">208</span>     gpgpu rlmedica    angel  R       1:37      <span style="color:#ae81ff">1</span> g01
</span></span></code></pre></div><p>We can see that our job is running (note the &lsquo;R&rsquo; value) on the g01 node. In case the job could not be run immediately (due to lack of resource availability at the moment, priority reasons, etc&hellip;) the state would be &lsquo;PD&rsquo; (which means &lsquo;Pending&rsquo;), and SLURM will keep it that way until the conditions for running it are met. Then it would be executed automatically (it would enter the &lsquo;R&rsquo; state). You can find detailed information about SLURM job states in the <strong><a href="https://slurm.schedmd.com/squeue.html#SECTION_JOB-STATE-CODES" target="_blank">SLURM documentation</a></strong></p>
<p>We can format the output of the <code>squeue</code> command to get a bit more information:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$ squeue -u angel -o <span style="color:#e6db74">&#34;%.5i %.6u %.9P %.8j %.8T %.6M %.12l %.5C %.10b %.10R&#34;</span>
</span></span><span style="display:flex;"><span>JOBID   USER PARTITION     NAME    STATE   TIME   TIME_LIMIT  CPUS TRES_PER_N NODELIST<span style="color:#f92672">(</span>REASON<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">208</span>  angel     gpgpu rlmedica  RUNNING   0:51   1-00:00:00    <span style="color:#ae81ff">10</span> gres:gpu:1        g01
</span></span></code></pre></div><p>Note the information regarding some of the resources we requested in our job script (10 CPUS, 1 GPU).</p>
<p>With the <code>scontrol</code>command we can get quite detailed information about our specific job:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$ scontrol show jobid -d <span style="color:#ae81ff">208</span>
</span></span><span style="display:flex;"><span>JobId<span style="color:#f92672">=</span><span style="color:#ae81ff">208</span> JobName<span style="color:#f92672">=</span>rlmedical-train01
</span></span><span style="display:flex;"><span>   UserId<span style="color:#f92672">=</span>angel<span style="color:#f92672">(</span>1000<span style="color:#f92672">)</span> GroupId<span style="color:#f92672">=</span>angel<span style="color:#f92672">(</span>1000<span style="color:#f92672">)</span> MCS_label<span style="color:#f92672">=</span>N/A
</span></span><span style="display:flex;"><span>   Priority<span style="color:#f92672">=</span><span style="color:#ae81ff">4294901713</span> Nice<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> Account<span style="color:#f92672">=(</span>null<span style="color:#f92672">)</span> QOS<span style="color:#f92672">=(</span>null<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>   JobState<span style="color:#f92672">=</span>RUNNING Reason<span style="color:#f92672">=</span>None Dependency<span style="color:#f92672">=(</span>null<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>   Requeue<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> Restarts<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> BatchFlag<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> Reboot<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> ExitCode<span style="color:#f92672">=</span>0:0
</span></span><span style="display:flex;"><span>   DerivedExitCode<span style="color:#f92672">=</span>0:0
</span></span><span style="display:flex;"><span>   RunTime<span style="color:#f92672">=</span>00:08:49 TimeLimit<span style="color:#f92672">=</span>1-00:00:00 TimeMin<span style="color:#f92672">=</span>N/A
</span></span><span style="display:flex;"><span>   SubmitTime<span style="color:#f92672">=</span>2023-05-02T22:06:42 EligibleTime<span style="color:#f92672">=</span>2023-05-02T22:06:42
</span></span><span style="display:flex;"><span>   AccrueTime<span style="color:#f92672">=</span>2023-05-02T22:06:42
</span></span><span style="display:flex;"><span>   StartTime<span style="color:#f92672">=</span>2023-05-02T22:06:43 EndTime<span style="color:#f92672">=</span>2023-05-03T22:06:43 Deadline<span style="color:#f92672">=</span>N/A
</span></span><span style="display:flex;"><span>   SuspendTime<span style="color:#f92672">=</span>None SecsPreSuspend<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> LastSchedEval<span style="color:#f92672">=</span>2023-05-02T22:06:43 Scheduler<span style="color:#f92672">=</span>Main
</span></span><span style="display:flex;"><span>   Partition<span style="color:#f92672">=</span>gpgpu AllocNode:Sid<span style="color:#f92672">=</span>avicenna:2636496
</span></span><span style="display:flex;"><span>   ReqNodeList<span style="color:#f92672">=(</span>null<span style="color:#f92672">)</span> ExcNodeList<span style="color:#f92672">=(</span>null<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>   NodeList<span style="color:#f92672">=</span>g01
</span></span><span style="display:flex;"><span>   BatchHost<span style="color:#f92672">=</span>g01
</span></span><span style="display:flex;"><span>   NumNodes<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> NumCPUs<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span> NumTasks<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> CPUs/Task<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span> ReqB:S:C:T<span style="color:#f92672">=</span>0:0:*:*
</span></span><span style="display:flex;"><span>   TRES<span style="color:#f92672">=</span>cpu<span style="color:#f92672">=</span>10,mem<span style="color:#f92672">=</span>30G,node<span style="color:#f92672">=</span>1,billing<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>   Socks/Node<span style="color:#f92672">=</span>* NtasksPerN:B:S:C<span style="color:#f92672">=</span>0:0:*:* CoreSpec<span style="color:#f92672">=</span>*
</span></span><span style="display:flex;"><span>   JOB_GRES<span style="color:#f92672">=</span>gpu:ampere:1
</span></span><span style="display:flex;"><span>     Nodes<span style="color:#f92672">=</span>g01 CPU_IDs<span style="color:#f92672">=</span>0-9 Mem<span style="color:#f92672">=</span><span style="color:#ae81ff">30720</span> GRES<span style="color:#f92672">=</span>gpu:ampere:1<span style="color:#f92672">(</span>IDX:0<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>   MinCPUsNode<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span> MinMemoryNode<span style="color:#f92672">=</span>30G MinTmpDiskNode<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>   Features<span style="color:#f92672">=(</span>null<span style="color:#f92672">)</span> DelayBoot<span style="color:#f92672">=</span>00:00:00
</span></span><span style="display:flex;"><span>   OverSubscribe<span style="color:#f92672">=</span>OK Contiguous<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> Licenses<span style="color:#f92672">=(</span>null<span style="color:#f92672">)</span> Network<span style="color:#f92672">=(</span>null<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>   Command<span style="color:#f92672">=</span>/home/angel/rl-medical_train.run
</span></span><span style="display:flex;"><span>   WorkDir<span style="color:#f92672">=</span>/home/angel
</span></span><span style="display:flex;"><span>   StdErr<span style="color:#f92672">=</span>/home/angel/job.208.err
</span></span><span style="display:flex;"><span>   StdIn<span style="color:#f92672">=</span>/dev/null
</span></span><span style="display:flex;"><span>   StdOut<span style="color:#f92672">=</span>/home/angel/job.208.out
</span></span><span style="display:flex;"><span>   Power<span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>   TresPerNode<span style="color:#f92672">=</span>gres:gpu:1
</span></span></code></pre></div><p>Additionally, we can get monitoring information of the GPU usage with the <strong><a href="https://developer.nvidia.com/nvidia-system-management-interface" target="_blank"><code>nvidia-smi</code></a></strong> tool. We can use the <strong><a href="https://slurm.schedmd.com/srun.html" target="_blank"><code>srun</code></a></strong> command (which allows us to submit jobs to SLURM interactively) to attach the ID of our job to <code>nvidia-smi</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>angel@avicenna ~<span style="color:#f92672">]</span>$ srun --jobid <span style="color:#ae81ff">208</span> nvidia-smi
</span></span><span style="display:flex;"><span>Tue May  <span style="color:#ae81ff">2</span> 22:22:27 <span style="color:#ae81ff">2023</span>
</span></span><span style="display:flex;"><span>+-----------------------------------------------------------------------------+
</span></span><span style="display:flex;"><span>| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |
</span></span><span style="display:flex;"><span>|-------------------------------+----------------------+----------------------+
</span></span><span style="display:flex;"><span>| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
</span></span><span style="display:flex;"><span>| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
</span></span><span style="display:flex;"><span>|                               |                      |               MIG M. |
</span></span><span style="display:flex;"><span>|<span style="color:#f92672">===============================</span>+<span style="color:#f92672">======================</span>+<span style="color:#f92672">======================</span>|
</span></span><span style="display:flex;"><span>|   <span style="color:#ae81ff">0</span>  NVIDIA GeForce ...  Off  | 00000000:43:00.0 Off |                  N/A |
</span></span><span style="display:flex;"><span>| 30%   35C    P8    11W / 350W |    543MiB / 24576MiB |      0%      Default |
</span></span><span style="display:flex;"><span>|                               |                      |                  N/A |
</span></span><span style="display:flex;"><span>+-------------------------------+----------------------+----------------------+
</span></span><span style="display:flex;"><span>|   <span style="color:#ae81ff">1</span>  NVIDIA GeForce ...  Off  | 00000000:88:00.0 Off |                  N/A |
</span></span><span style="display:flex;"><span>| 30%   40C    P0   101W / 350W |      0MiB / 24576MiB |      0%      Default |
</span></span><span style="display:flex;"><span>|                               |                      |                  N/A |
</span></span><span style="display:flex;"><span>+-------------------------------+----------------------+----------------------+
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>+-----------------------------------------------------------------------------+
</span></span><span style="display:flex;"><span>| Processes:                                                                  |
</span></span><span style="display:flex;"><span>|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
</span></span><span style="display:flex;"><span>|        ID   ID                                                   Usage      |
</span></span><span style="display:flex;"><span>|<span style="color:#f92672">=============================================================================</span>|
</span></span><span style="display:flex;"><span>|    <span style="color:#ae81ff">0</span>   N/A  N/A    <span style="color:#ae81ff">101488</span>      C   python                            541MiB |
</span></span><span style="display:flex;"><span>+-----------------------------------------------------------------------------+
</span></span></code></pre></div><p>Note that in this way, we are submitting an additional job step to SLURM, but using the same allocated resources of your original job (anyway the required resources for the <code>nvidia-smi</code>job step should be minimal and should not noticeably influence your original job performance).</p>
<p>As the output above shows, we can get detailed information about the GPUs usage on the node our job is running on. We can see that our job is running on the first GPU out of the two installed, the GPU memory usage, temperature, wattage, etc&hellip;</p>

            <footer class="footline">
            </footer>
          </article>
        </div>
      </main>
    </div>
    <aside id="sidebar" class="default-animation">
      <div id="header-wrapper" class="default-animation">
        <div id="header" class="default-animation">
<a id="logo" href="/clustertut"><img src="/clustertut/images/ueb-notext-bw.png" width=156px height=65px></a>
        </div>
        <div class="searchbox default-animation">
          <i class="fas fa-search" title="Search (CTRL+ALT+f)"></i>
          <label class="a11y-only" for="search-by">Search</label>
          <input data-search-input id="search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
          <span data-search-clear=""><i class="fas fa-times"></i></span>
        </div>
        <script>
          var contentLangs=['en'];
        </script>
        <script src="/clustertut/js/auto-complete.js?1683059874" defer></script>
        <script src="/clustertut/js/lunr/lunr.min.js?1683059874" defer></script>
        <script src="/clustertut/js/lunr/lunr.stemmer.support.min.js?1683059874" defer></script>
        <script src="/clustertut/js/lunr/lunr.multi.min.js?1683059874" defer></script>
        <script src="/clustertut/js/lunr/lunr.en.min.js?1683059874" defer></script>
        <script src="/clustertut/js/search.js?1683059874" defer></script>
      </div>
      <div id="content-wrapper" class="highlightable">
        <ul class="topics">
          <li data-nav-id="/clustertut/basics/index.html" class="dd-item"><a href="/clustertut/basics/index.html">Basics</a><ul id="subsections-3494ad44d160b070fd31576fe4a3841e">
          <li data-nav-id="/clustertut/basics/connecting/index.html" class="dd-item"><a href="/clustertut/basics/connecting/index.html">Accessing the cluster</a></li>
          <li data-nav-id="/clustertut/basics/storage_users/index.html" class="dd-item"><a href="/clustertut/basics/storage_users/index.html">Storage available to users</a></li></ul></li>
          <li data-nav-id="/clustertut/practical-examples/index.html" class="dd-item parent"><a href="/clustertut/practical-examples/index.html">Practical Examples</a><ul id="subsections-a70580eb17b66487329cb6446056eecb">
          <li data-nav-id="/clustertut/practical-examples/example_pre-installed/index.html" class="dd-item"><a href="/clustertut/practical-examples/example_pre-installed/index.html">Pre-installed software: RNA-Seq QC</a></li>
          <li data-nav-id="/clustertut/practical-examples/example_singularity/index.html" class="dd-item"><a href="/clustertut/practical-examples/example_singularity/index.html">Singularity: Quasi-mapping RNA-Seq quantification</a></li>
          <li data-nav-id="/clustertut/practical-examples/example_gpu-conda/index.html" class="dd-item active"><a href="/clustertut/practical-examples/example_gpu-conda/index.html">GPU job: RL-Medical with conda</a></li></ul></li>
        </ul>
        <div class="footermargin footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"></div>
        <hr class="default-animation footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter">
        <div id="prefooter" class="footerLangSwitch footerVariantSwitch footerVisitedLinks">
          <ul>
            <li id="select-language-container" class="footerLangSwitch">
              <div class="padding select-container">
                <i class="fas fa-language fa-fw"></i>
                <span>&nbsp;</span>
                <div class="select-style">
                  <label class="a11y-only" for="select-language">Language</label>
                  <select id="select-language" onchange="location = baseUri + this.value;">
                  </select>
                </div>
                <div class="select-clear"></div>
              </div>
            </li>
            <li id="select-variant-container" class="footerVariantSwitch">
              <div class="padding select-container">
                <i class="fas fa-paint-brush fa-fw"></i>
                <span>&nbsp;</span>
                <div class="select-style">
                  <label class="a11y-only" for="select-variant">Theme</label>
                  <select id="select-variant" onchange="window.variants && variants.changeVariant( this.value );">
                    <option id="learn" value="learn" selected>Learn</option>
                  </select>
                </div>
                <div class="select-clear"></div>
              </div>
              <script>window.variants && variants.markSelectedVariant();</script>
            </li>
            <li class="footerVisitedLinks"><button class="padding" onclick="clearHistory();"><i class="fas fa-history fa-fw"></i> Clear History</button></li>
          </ul>
        </div>
        <div id="footer" class="footerFooter showFooter">
	    <p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p>
        </div>
      </div>
    </aside>
    <script src="/clustertut/js/clipboard.min.js?1683059874" defer></script>
    <script src="/clustertut/js/perfect-scrollbar.min.js?1683059874" defer></script>
    <script src="/clustertut/js/theme.js?1683059874" defer></script>
  </body>
</html>
